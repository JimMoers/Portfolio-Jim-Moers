---
title: "Portfolio Jim Moers"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: scroll
    storyboard: true
---
```{r setup, include=FALSE}
library(spotifyr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(plotly)
library(compmus)
Floating_Points <- get_playlist_audio_features("", "5KebRTYjItlSsLlUE1Im2E")
Pharoah_Sanders <- get_playlist_audio_features("", "4T277sUcE2zOO4jW3FVl04")
London_Symphony_Orchestra <- get_playlist_audio_features("","5oka6nlrTGK22717u1lgjf")
Promises <- get_playlist_audio_features("", "1h68Oc6QFWEUaCRnR69Co9")    
combined <- rbind(Floating_Points, Pharoah_Sanders, London_Symphony_Orchestra, Promises)    
```

Introduction
=============================================================

For this project my corpus will be about three artists: Floating Points, Pharoa Sanders and the London Symphony Orchestra. These are three artist from very different genres. Floating Points makes mostly idm and dance music, Pharoa Sanders is known for his free jazz and avant-garde jazz and the London Symphony Orchestra plays classical music. However, these three artists released the collaborative album "Promises" last year, which is a classical album with jazz and electronic influences. In my reasearch I want to compare the work of the individual artists to their collaborative albums. With this I think it could be interesting to see where the similarities and the differences are of the artists. To represent each artist I will be using their "this is..." playlist from spotify, which contain the songs that represent the artists the most. I've edited the playlists to take out the songs that are also on "Promises" to make sure the songs won't be compared with themselves. 



Exploratory graphs
===========================================================
In this first chapter, some graphs are going to be made with which the three individual artists can be compared to their collaborative album. 

### Graph 1: boxplot of valence
This plot shows a boxplot of valence, which is the measure Spotify uses to measure the "hapiness" of a piece of music. Low valence is seen as music that sounds sadder and high valence is seen as happier. A boxplot is used because it is good at showing both the median of a variable and how spread out the data is. 

In this boxplot, the first thing that can be noticed is that both the median valence and the spread of the valence is almost equal when comparing Promises with the London symphony Orchestra. Both have a valence that is very low with a median of 0.07


### figure 1: Boxplot of valence
```{r, echo = FALSE}

boxplot_valence <- ggplot(combined, aes(x = playlist_name, y = valence)) +
  geom_boxplot() 

ggplotly(boxplot_valence)
```


### graph 2: Danceability and tempo
Comparing the tempo and danceability of the artists shows that mosts of Promises's songs are below 100 bpm and not very danceable. The artist thats closest to this is The London Symphony Orchestra. They have some faster songs, but most are below 100 bpm. Almost all of their songs are below 0.5 danceability and most even below 0.25. Floating Points has many songs that have a danceability above 0.5. Almost all of these are between 100 and 150 bpm. He has some songs which are less danceable, and most of these are below 100 bpm. Most of Pharoa Sander's songs are below 0.5 danceability, but most of his songs have a higher tempo. 

### figure 2: scatterplot of danceability and tempo
```{r, echo = FALSE}

scatter_danceability_tempo <- ggplot(combined, aes(x = danceability, y = tempo, color = playlist_name)) +
  geom_point()

ggplotly(scatter_danceability_tempo)
```

Chromagram and Self Similarity Matrices
===================================================
For the chromagram and Self similarity matrices the song Movement 2 from the colaborative album Promises was used. This song was chosen because there is a shift in instrumentation in the middle of the song and it would be interesting to see how this translates into the data.

### Chromagram
This song translates very well into a chromagram. The song starts with long drawn out strings that hold a note for a long time, this is very visible in the chromagram. At around 65 seconds a saxophone starts playing, he starts and ends this section by holding very long notes, as seen by the big yellow bars on D#/Eb. 

### figure 3: chromagram of Movement 2
``` {r, echo = FALSE}
movement_2 <-
  get_tidy_audio_analysis("7Dz3hFXlpXZQ1BRoxAnQtP") %>%
  select(segments)%>%
  unnest(segments)%>%
  select(start, duration, pitches)

movement_2 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

### Self similarity matrix

The shift in the middle is also very visible in the self similarity matrices. On the left is the self similarity matrix of the timbre and on the right the self similarity matrix of the pitch. Both see a big shift in the middle of the song where the saxophone comes in, in the pitch matrix more than the timbre matrix, which makes sense, because the instruments that where there before the saxophone starts are still present in the background, so the shift in timbre isn't that big.

### figure 4: self similarity matrices of Movement 2
```{r, echo = FALSE}
movement_2 <-
  get_tidy_audio_analysis("7Dz3hFXlpXZQ1BRoxAnQtP") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
          compmus_summarise, timbre,
          method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

movement_2 %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

movement_2 %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```

Key analysis
============================================================

### Keygram

For making a keygram I thought the piece Movement 6 of the colaborative album would be the most interesting. In this song the strings are slowly building op to an intense climax. However, when looking at this Keygram, it is hard to find any real key structure. This could be because the song is not very structured and is just a long build up. 

### figure 5: keygram of Movement 6
```{r, echo = FALSE}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
movement_6 <-
  get_tidy_audio_analysis("15JPLvzw97Nmf54scG5tqH") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
          compmus_summarise, pitches,
          method = "mean", norm = "manhattan"
      )
  )

movement_6 %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

### Key histogram
To see the variation of keys the artists songs are in, a histogram was made. By looking at this, the first thing that stands out is that almost all songs on Promises are in the same key (C). There are only two songs on the album that are not in the C key. The london symphony also has a lot of songs in the C key, as well as Pharoah Sanders, but both artists have many songs in other keys. Most of Floating Points's songs are in the F key. 

### figure 6: histogram of keys of whole corpus
``` {r, echo = FALSE}
histogram_keys <- ggplot(combined, aes(key, fill = playlist_name)) +
  geom_histogram()

ggplotly(histogram_keys)
```

Tempo data
============================================================
### tempogram
For the tempogram I wanted to create a tempogram for one of the songs of the Promises album, but because there is almost no beat or percussion on that album, it was not possible to make a good tempogram. So I decided to make a tempogram for the idm song LesAlpx by floating points. As seen in the tempogram it has a beat that goes on for most of the song, with the notable exeption of the section around 2 minutes, there the beat stops for a short while before coming back into the song. 

### figure 7: tempogram of LesAlpx
```{r, echo = FALSE}
LesAlpx <- get_tidy_audio_analysis("3PhICIIH9dua2ZZryHqiHE")

LesAlpx %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

### Histogram of tempo's
To get a better insight of of how the artists compare to eachother in terms of tempo, I've made a histogram of the tempo's from the playlists. What stands out most is how often a tempo of 130bpm is used in comparison to other tempo's. This is mostly because pharoa sanders has many songs in that tempo. Also noteworthy is that there are not many songs at 100 bpm. The London Symphony Orchestra mostly has songs that are slower. 
### figure 8: Histogram of tempo's of entire corpus
``` {r, echo = FALSE}
histogram_tempo <- ggplot(combined, aes(tempo, fill = playlist_name)) +
  geom_histogram()

ggplotly(histogram_tempo)

